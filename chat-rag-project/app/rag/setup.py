# RAG åŸºç¡€å±‚ï¼šè´Ÿè´£çŸ¥è¯†åº“çš„æ„å»ºå’ŒåŠ è½½ (å‘é‡å­˜å‚¨)
from fileinput import filename
import os
from langchain_community.document_loaders import UnstructuredMarkdownLoader
from langchain_chroma import Chroma
from langchain_ollama import OllamaEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter


OLLAMA_EMBEDDING_MODEL = os.environ.get("OLLAMA_EMBEDDING_MODEL_NAME", "nomic-embed-text")
CHROMA_PATH = os.environ.get("CHROMA_DB_PATH", "chroma_data")
RAG_DOCS_PATH = os.environ.get("RAG_DOCS_PATH", "rag_docs")

if not os.path.exists(RAG_DOCS_PATH):
    os.makedirs(RAG_DOCS_PATH)
    with open(os.path.join(RAG_DOCS_PATH, "README.md"),
              "w",
              encoding="utf-8") as f:
        f.write("# LangChain LCEL æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºå¤æ‚ LLM åº”ç”¨ç¨‹åºçš„å¼ºå¤§å·¥å…·ã€‚å®ƒæ”¯æŒæµå¼ä¼ è¾“ã€å¹¶è¡Œæ‰§è¡Œå’Œè¿è¡Œæ—¶æ£€æŸ¥ã€‚LangServe æ˜¯éƒ¨ç½² LCEL é“¾çš„é¦–é€‰æ–¹å¼ã€‚æœ¬é¡¹ç›®ä½¿ç”¨ Ollama ä½œä¸º LLM å’ŒåµŒå…¥æ¨¡å‹ã€‚")

def get_vector_store():
    """
    åŠ è½½æ–‡æ¡£ï¼Œåˆ†å‰²ï¼ŒåµŒå…¥ï¼Œå¹¶åˆ›å»ºæˆ–åŠ è½½å‘é‡å­˜å‚¨ã€‚
    æ­¤å‡½æ•°è¿”å›ä¸€ä¸ªå‘é‡å­˜å‚¨å¯¹è±¡ã€‚
    """
    embeddings = OllamaEmbeddings(
            model=OLLAMA_EMBEDDING_MODEL,
            base_url=os.environ.get("OLLAMA_BASE_URL", "http://localhost:11434")
        )
    if os.path.exists(CHROMA_PATH) and os.listdir(CHROMA_PATH):
        print("ğŸ’¡ çŸ¥è¯†åº“å·²å­˜åœ¨,æ­£åœ¨åŠ è½½...")
        vector_store = Chroma(
            persist_directory=CHROMA_PATH,
            embedding_function=embeddings
        )
        return vector_store
    print("âœ¨ æ­£åœ¨åˆ›å»ºçŸ¥è¯†åº“...")
    # 1ï¸âƒ£load
    docs = []
    for filename in os.listdir(RAG_DOCS_PATH):
        if filename.endswith(".md"):
            loader = UnstructuredMarkdownLoader(os.path.join(RAG_DOCS_PATH, filename))
            docs.extend(loader.load())
    if not docs:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ–‡æ¡£ã€‚")
        return None
    # 2ï¸âƒ£split
    # åˆ›å»ºæ–‡æœ¬åˆ†å‰²å™¨
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=100,
    )
    # åˆ†å‰²æ–‡æ¡£
    split = text_splitter.split_documents(docs)
    # 3ï¸âƒ£embed
    vector_store = Chroma.from_documents(
        documents=split,
        embedding=embeddings,
        persist_directory=CHROMA_PATH
    )
    print("âœ… çŸ¥è¯†åº“åˆ›å»ºæˆåŠŸï¼Œå…± {len(splits)} ä¸ªæ–‡æ¡£ç‰‡æ®µã€‚")
    return vector_store
    

        
